{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set wrangle in the project is the tweet archives of Twitter user [@dog_rates](https://twitter.com/dog_rates) also known as [WeRateDogs](https://en.wikipedia.org/wiki/WeRateDogs). WeRateDogs is a Twitter account that rates peopleâ€™s dogs with a humorous comment about the dog.\n",
    "\n",
    "The WeRateDogs Twitter project goals included:\n",
    "\n",
    "  A. Wrangling the twitter data through the following process:-\n",
    "  \n",
    "      1. Gathering Data\n",
    "      2. Assessing Data\n",
    "      3. Cleaning Data\n",
    "      \n",
    "  B. Storing, Analysing and Visualizing your wrangled data\n",
    "  \n",
    "  C. Reporting on the data wrangling effort, data analyze and visualization\n",
    "  \n",
    "#### Gathering Data\n",
    "\n",
    "The data was gathered from three different datasets described below:\n",
    "\n",
    "Twitter archive file: The WeRateDogs Twitter archive: twitter_archive_enhanced.csv\n",
    "\n",
    "Tweet image predictions: The tweet image predictions (image_predictions.tsv) i.e., what breed of dog (or other object, animal, etc.) is present in each tweet according to a neural network.\n",
    "\n",
    "Twitter API data: Each tweet's retweet count and favorite (\"like\") count was collected using the tweet IDs in the WeRateDogs Twitter archive by querying the Twitter API for each tweet's JSON data using Python's Tweepy library and storing each tweet's entire set of JSON data in a file called tweet_json.txt file.\n",
    "\n",
    "#### Assessing Data\n",
    "\n",
    "After gathering each of the above pieces of data, the data from the three datasets was assessed visually (using Excel) and programmatically (using pandas) for quality and tidiness issues.\n",
    "\n",
    "The following issues were found:\n",
    "\n",
    "Quality issues\n",
    "\n",
    "1. timestamp 'object' datatype.\n",
    "\n",
    "2. twitter archive data contains retweets\n",
    "\n",
    "3. name has values that are string 'None' instead of NaN & some values have unusual names of less than 3 characters such as 'an','a'.\n",
    "\n",
    "4. Some tweets are not about dogs, so doesn't contain rating\n",
    "\n",
    "5. Some of the ratings contain decimal \n",
    "\n",
    "6. Missing rows in image prediction dataset (2075 rows instead of 2356) either some tweets didn't have dog images or rows are missing.\n",
    "\n",
    "7. p1, p2, and p3 contains underscores instead of spaces in the string.\n",
    "\n",
    "8. tweet_id is an integer\n",
    "\n",
    "9. Remove columns no longer needed\n",
    "\n",
    "10. There are some duplicate jpg_urls.\n",
    "\n",
    "Tidiness issues\n",
    "\n",
    "1. Combine the 4 dog stage columns into a single column in the archive table\n",
    "\n",
    "2. The different dataframes should be merged into a single one.\n",
    "\n",
    "#### Cleaning Data\n",
    "\n",
    "The various quality and tidiness issues found during assessing data were solved in this cleaning step using pandas.\n",
    "\n",
    "First, all three datasets were merged into a single dataset (dataframe). Then, the various tidiness and quality issues (e.g. related to name and rating) were solved.\n",
    "\n",
    "Finally, the cleaned data was exported to a csv file, twitter_archive_master.csv.\n",
    "\n",
    "#### Visualization\n",
    "\n",
    "The master dataset was then analyzed and visualized to drive insights.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
